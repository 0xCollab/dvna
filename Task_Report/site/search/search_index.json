{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Table of contents The following is the report/documentation for the problem statement stated below. The contents of the report are: Problem Statement Setting Up VMs Static Analysis Comparing SAST Tools Setting Up Pipeline Configuring Webhook Deploying the Report` Resources This documentation can also be found online .","title":"Introduction"},{"location":"#table-of-contents","text":"The following is the report/documentation for the problem statement stated below. The contents of the report are: Problem Statement Setting Up VMs Static Analysis Comparing SAST Tools Setting Up Pipeline Configuring Webhook Deploying the Report` Resources This documentation can also be found online .","title":"Table of contents"},{"location":"comparing_sast_tools/","text":"Comparing SAST Tools A comparitive look at the various findings the various tools had. Vulnerability Reports Generated The following are the various vulnerabilities found by the tools used to perform SAST on DVNA: SonarQube SonarQube didn't find any security vulnerabilities. It, instead, found linting and syntax based bugs. NPM Audit NPM Audit found 5 security vulnerabilities: 3 Critical 1 High 1 Low Vulnereble modules identified: mathjs (2 Critical Vulnerabilities) node-serialize (1 Critical Vulnerability) typed-function (1 High Vulnerability) express-fileupload (1 Low Vulnerability) NodeJsScan NodeJsScan found a 34 dependency-based vulnerabilities: Deserialization with Remote Code Execution (8 Vulnerabilities) Open Redirect (1 Vulnerabilities) SQL Injection (1 Vulnerabilities) Secrete Hardcoded (1 Vulnerabilities) Server Side Injection (1 Vulnerabilities) Unescaped Variables (12 Vulnerabilities) Weak Hash Used (11 Vulnerabilities) Additionally, NodeJsScan found 5 web-based vulnerabilities: Missing Header Strict-Transport-Security (HSTS) Public-Key-Pin (HPKP) X-XSS-Protection X-Download-Options Information Disclosure X-Powered-By Retire.js Retire.js found 3 security vulnerabilities: 1 High 1 Medium 1 Low Vulnerable modules identified: node-serialize 0.0.4 (High) jquery 2.1.1 (Medium) jquery 3.2.1 (Low) OWASP Dependency Check Dependency-Check identified 7 security vulnerabilities: 3 Critical 1 High 2 Medium 1 Low Vulnerable modules identified: mathjs 3.10.1 (Critical) node-serialize 0.0.4 (Critical) sequelize 4.44.3 (Critical) typed-function 0.10.5 (High) jquery-2.1.1.min.js (Medium) jquery-3.2.1.min.js (Medium) express-fileupload 0.4.0 (Low) Auditjs Auditjs found 22 security vulnerabilities in the 5 vulnerable modules identified: Nodejs 8.10.0 (14 Vulnerabilities) mathjs 3.10.1 (3 Vulnerabilities) typed-function 0.10.5 (2 Vulnerabilities) sequelize 4.44.3 (2 Vulnerabilities) express-fileupload 0.4.0 (1 Vulnerability) Snyk Snyk indentifeid 8 security vulnerabilities: 6 High: express-fileupload (Denial of Service; 1 Vulnerability) typed-function (Arbitary Code Execution; 1 Vulnerability) mathjs (Arbitary Code Execution; 3 Vulnerabilities) node-serialize (Arbitary Code Execution; 1 Vulnerability) 2 Medium: mathjs (Arbitary Code Execution; 2 Vulnerabilities) Conclusion Based on the reports generated and the vulnerabilities found by the various scanner used to analyse DVNA, the ranking of these tools from best to worse (in my opinion) is as follows: NodeJsScan (34 dependency-based + 5 web-based) Auditjs (22) Snyk (8) OWASP Dependency Check (7) NPM Audit (5) Retire.js (3) SonarQube (0)","title":"Comparing SAST Tools"},{"location":"comparing_sast_tools/#comparing-sast-tools","text":"A comparitive look at the various findings the various tools had.","title":"Comparing SAST Tools"},{"location":"comparing_sast_tools/#vulnerability-reports-generated","text":"The following are the various vulnerabilities found by the tools used to perform SAST on DVNA:","title":"Vulnerability Reports Generated"},{"location":"comparing_sast_tools/#sonarqube","text":"SonarQube didn't find any security vulnerabilities. It, instead, found linting and syntax based bugs.","title":"SonarQube"},{"location":"comparing_sast_tools/#npm-audit","text":"NPM Audit found 5 security vulnerabilities: 3 Critical 1 High 1 Low Vulnereble modules identified: mathjs (2 Critical Vulnerabilities) node-serialize (1 Critical Vulnerability) typed-function (1 High Vulnerability) express-fileupload (1 Low Vulnerability)","title":"NPM Audit"},{"location":"comparing_sast_tools/#nodejsscan","text":"NodeJsScan found a 34 dependency-based vulnerabilities: Deserialization with Remote Code Execution (8 Vulnerabilities) Open Redirect (1 Vulnerabilities) SQL Injection (1 Vulnerabilities) Secrete Hardcoded (1 Vulnerabilities) Server Side Injection (1 Vulnerabilities) Unescaped Variables (12 Vulnerabilities) Weak Hash Used (11 Vulnerabilities) Additionally, NodeJsScan found 5 web-based vulnerabilities: Missing Header Strict-Transport-Security (HSTS) Public-Key-Pin (HPKP) X-XSS-Protection X-Download-Options Information Disclosure X-Powered-By","title":"NodeJsScan"},{"location":"comparing_sast_tools/#retirejs","text":"Retire.js found 3 security vulnerabilities: 1 High 1 Medium 1 Low Vulnerable modules identified: node-serialize 0.0.4 (High) jquery 2.1.1 (Medium) jquery 3.2.1 (Low)","title":"Retire.js"},{"location":"comparing_sast_tools/#owasp-dependency-check","text":"Dependency-Check identified 7 security vulnerabilities: 3 Critical 1 High 2 Medium 1 Low Vulnerable modules identified: mathjs 3.10.1 (Critical) node-serialize 0.0.4 (Critical) sequelize 4.44.3 (Critical) typed-function 0.10.5 (High) jquery-2.1.1.min.js (Medium) jquery-3.2.1.min.js (Medium) express-fileupload 0.4.0 (Low)","title":"OWASP Dependency Check"},{"location":"comparing_sast_tools/#auditjs","text":"Auditjs found 22 security vulnerabilities in the 5 vulnerable modules identified: Nodejs 8.10.0 (14 Vulnerabilities) mathjs 3.10.1 (3 Vulnerabilities) typed-function 0.10.5 (2 Vulnerabilities) sequelize 4.44.3 (2 Vulnerabilities) express-fileupload 0.4.0 (1 Vulnerability)","title":"Auditjs"},{"location":"comparing_sast_tools/#snyk","text":"Snyk indentifeid 8 security vulnerabilities: 6 High: express-fileupload (Denial of Service; 1 Vulnerability) typed-function (Arbitary Code Execution; 1 Vulnerability) mathjs (Arbitary Code Execution; 3 Vulnerabilities) node-serialize (Arbitary Code Execution; 1 Vulnerability) 2 Medium: mathjs (Arbitary Code Execution; 2 Vulnerabilities)","title":"Snyk"},{"location":"comparing_sast_tools/#conclusion","text":"Based on the reports generated and the vulnerabilities found by the various scanner used to analyse DVNA, the ranking of these tools from best to worse (in my opinion) is as follows: NodeJsScan (34 dependency-based + 5 web-based) Auditjs (22) Snyk (8) OWASP Dependency Check (7) NPM Audit (5) Retire.js (3) SonarQube (0)","title":"Conclusion"},{"location":"configuring_webhook/","text":"Configuring Trigger with Webhook Objective The aim of this section is to create and configure a webhook to automate builds based on defined events occuring on the project repository in reference to 8th point's second section in the problem statement . Webhooks Webhooks, sometimes referred to as Reverse APIs , are functions that are triggered on the occurrence of selected events. These functions, generally, are used to notify a different interface/endpoint about the occurence of the event. To build and deploy the application based on push events and new releases on the project repository on GitHub automatically, I needed a Jenkins Webhook to handle a trigger that GitHub will send when selected events occur. GitHub Authentication for Webhook Jenkins needs to be authenticated with GitHub for it to be able to handle a webhook. For this authentication, I needed a Personal Access Token or PAT on GitHub. I generated a PAT for Jenkins using this documentation . I used this documentation as it was GithHub's own. In the first section, 'Creating a token', the 7th step is where one has to choose the access that the token grants the application using the token. Here, I chose everything under the 'repo' option and nothing else as I was only concerned about push events. Out of the two sections present in the documentation, I skipped the second one, 'Using a token on the command line', as it was not required in the solution for the problem statement. Configuring Jenkins for Webhook The PAT generated above is then added as a Secret Text Credential in Jenkins under Credentials > Add New Credential . Added GitHub Server under Manage Jenkins > Configure System with Personal Access Token generated as a Credential in Jenkins. The API URL used is https://api.github.com and the Manage Hooks option is checked. Selected the GitHub hook trigger for GITScm polling option under Build triggers for the particular Jenkins project. Configuring GitHub for Webhook On GitHub, we need to add the Webhook to the project repository. The following are the steps to add a Webhook for a GitHub Project: We go to the project repository, and there we navigate to Settings > Webhooks and click on Add Webhook option. The Payload URL is where we put our Jenkins Servers domain/IP appended with /github-webhook/ at the end. For example, http://{JENKINS VM IP}/github-webhook/ is a valid Jenkins Webhook. The Content Type should be application/json . Then the required events are selected (Pushes & Releases in this case). The Active option is checked. Save the Webhook. Using ngrok to handle Webhook over Internet If we do not have a public IP to handle GitHub's webhook triggers over the web, we can use ngrok to provide us with a domain that points to our machine. All the steps below are performed on the Jenkins VM. ngrok runs as an executable which can be downloaded from here on the Jenkins VM. Unzip the downloaded file as follows: unzip /path/to/ngrok.zip Sign up for an account to get an Authentication Token and then authenticate ngrok for initialization as follows: ./ngrok authtoken <AUTH_TOKEN> To run ngrok and start a HTTP Tunnel, we use the following command: ./ngrok http 8080 Note : We use port 8080, instead of 80, as our instance of Jenkins is running on 8080. Lastly, we take the URL provided by ngrok , append /github-webhook at the end, and use it as the PAYLOAD URL on GitHub for the Webhook.","title":"Configuring Webhook"},{"location":"configuring_webhook/#configuring-trigger-with-webhook","text":"","title":"Configuring Trigger with Webhook"},{"location":"configuring_webhook/#objective","text":"The aim of this section is to create and configure a webhook to automate builds based on defined events occuring on the project repository in reference to 8th point's second section in the problem statement .","title":"Objective"},{"location":"configuring_webhook/#webhooks","text":"Webhooks, sometimes referred to as Reverse APIs , are functions that are triggered on the occurrence of selected events. These functions, generally, are used to notify a different interface/endpoint about the occurence of the event. To build and deploy the application based on push events and new releases on the project repository on GitHub automatically, I needed a Jenkins Webhook to handle a trigger that GitHub will send when selected events occur.","title":"Webhooks"},{"location":"configuring_webhook/#github-authentication-for-webhook","text":"Jenkins needs to be authenticated with GitHub for it to be able to handle a webhook. For this authentication, I needed a Personal Access Token or PAT on GitHub. I generated a PAT for Jenkins using this documentation . I used this documentation as it was GithHub's own. In the first section, 'Creating a token', the 7th step is where one has to choose the access that the token grants the application using the token. Here, I chose everything under the 'repo' option and nothing else as I was only concerned about push events. Out of the two sections present in the documentation, I skipped the second one, 'Using a token on the command line', as it was not required in the solution for the problem statement.","title":"GitHub Authentication for Webhook"},{"location":"configuring_webhook/#configuring-jenkins-for-webhook","text":"The PAT generated above is then added as a Secret Text Credential in Jenkins under Credentials > Add New Credential . Added GitHub Server under Manage Jenkins > Configure System with Personal Access Token generated as a Credential in Jenkins. The API URL used is https://api.github.com and the Manage Hooks option is checked. Selected the GitHub hook trigger for GITScm polling option under Build triggers for the particular Jenkins project.","title":"Configuring Jenkins for Webhook"},{"location":"configuring_webhook/#configuring-github-for-webhook","text":"On GitHub, we need to add the Webhook to the project repository. The following are the steps to add a Webhook for a GitHub Project: We go to the project repository, and there we navigate to Settings > Webhooks and click on Add Webhook option. The Payload URL is where we put our Jenkins Servers domain/IP appended with /github-webhook/ at the end. For example, http://{JENKINS VM IP}/github-webhook/ is a valid Jenkins Webhook. The Content Type should be application/json . Then the required events are selected (Pushes & Releases in this case). The Active option is checked. Save the Webhook.","title":"Configuring GitHub for Webhook"},{"location":"configuring_webhook/#using-ngrok-to-handle-webhook-over-internet","text":"If we do not have a public IP to handle GitHub's webhook triggers over the web, we can use ngrok to provide us with a domain that points to our machine. All the steps below are performed on the Jenkins VM. ngrok runs as an executable which can be downloaded from here on the Jenkins VM. Unzip the downloaded file as follows: unzip /path/to/ngrok.zip Sign up for an account to get an Authentication Token and then authenticate ngrok for initialization as follows: ./ngrok authtoken <AUTH_TOKEN> To run ngrok and start a HTTP Tunnel, we use the following command: ./ngrok http 8080 Note : We use port 8080, instead of 80, as our instance of Jenkins is running on 8080. Lastly, we take the URL provided by ngrok , append /github-webhook at the end, and use it as the PAYLOAD URL on GitHub for the Webhook.","title":"Using ngrok to handle Webhook over Internet"},{"location":"deploying_report/","text":"Deploying Report with MkDocs Objective The aim of this section is to create a documentation in Markdown and use MkDocs to deploy the documentation generated as a static site in reference to the 7th point of the problem statement . Format and Tools The report was written in Markdown as required by the problem statement. Markdown is a markup language which allows text formatting using a defined syntax. It is used extensively for documentation and can be converted to various other formats, including HTML, which allows many tools to build static sites with markdown documentation. MkDocs was the tool used, as reqiured by the problem statement, to build a static site with the report. MkDocs is a static site generator which creates sites with content written in Markdown and the site is configured with a YAML (YAML is a human-friendly data serialization standard and has various applications) file. Installing MkDocs I installed MkDocs with the command 'pip install mkdocs' as mentioned in the official documentation . I only referred to the 'Installing MkDocs' section under 'Manual Installation' as rest of the steps were not required in the context of the task/problem statement. Selecting a Theme MkDocs allows users to use various themes to customise the style and look of the site. For the report's site generated with MkDocs to look nice, I used the 'Material' theme as suggested during the preliminary review of the task. To use this theme with MkDocs, it is required to be installed with pip so, I installed Material theme using the command 'pip install mkdocs-material' as mentioned in the official documentation . Lastly, I specified the theme in MkDocs's configuration YAML file which can be seen in the next section. Site Configuration To build the static site, MkDocs needs a YAML file, called mkdocs.yml , be present in the root directory of the project that configures the site structure, site title, pages, themes, etc. It is used to define properties for the site. The YAML file that I wrote for the report is below: site_name: 'Jenkins Pipeline' pages: - Introduction: 'index.md' - Problem Statement: 'problem_statement.md' - Glossary: 'glossary.md' - Setting Up VMs: 'setting_up_vms.md' - Static Analysis: 'static_analysis.md' - Comparing SAST Tools: 'comparing_sast_tools.md' - Setting Up Pipeline: 'setting_up_pipeline.md' - Configuring Webhook: 'configuring_webhook.md' - Deploying the Report: 'deploying_report.md' - Resources: 'resources.md' theme: 'material' site_name defines the title for the site generated by MkDocs. pages defines the various pages that the site will consist of. Within this section, the title for the different pages, along with the Markdown file they are to be associated with, are also declared in a key-value pair structure. theme defines which theme MkDocs should use while generating/serving the static site. Deploying Static Site To generate the static site, in the root directory of the report, I ran the command 'mkdocs build' as mentioned in the documentation. This creates a /site directory containing all the required files to deploy the site. Note : To just preview how the site looks, I used 'mkdocs serve' in the terminal to serve the site locally on my machine. Now, to serve the site I needed a web server for which I installed Apache , following Digital Ocean's documentation , as the server. I chose Apache as it is popular, has great support and is easy to work with in my opinion. The documentation was concise and complete in the context of the task and hence, I went with it. I, however, skipped step 4, 'Setting Up Virtual Hosts', as I was only going to host one site and thus, did not require to configure virtual hosts which are used to serve multiple websites on the same server. Lastly, I copied the contents from static site directory ( /site ) generated with MkDocs to the web root directory ( /var/www/html ) to serve the report as a static site.","title":"Deploying the Report"},{"location":"deploying_report/#deploying-report-with-mkdocs","text":"","title":"Deploying Report with MkDocs"},{"location":"deploying_report/#objective","text":"The aim of this section is to create a documentation in Markdown and use MkDocs to deploy the documentation generated as a static site in reference to the 7th point of the problem statement .","title":"Objective"},{"location":"deploying_report/#format-and-tools","text":"The report was written in Markdown as required by the problem statement. Markdown is a markup language which allows text formatting using a defined syntax. It is used extensively for documentation and can be converted to various other formats, including HTML, which allows many tools to build static sites with markdown documentation. MkDocs was the tool used, as reqiured by the problem statement, to build a static site with the report. MkDocs is a static site generator which creates sites with content written in Markdown and the site is configured with a YAML (YAML is a human-friendly data serialization standard and has various applications) file.","title":"Format and Tools"},{"location":"deploying_report/#installing-mkdocs","text":"I installed MkDocs with the command 'pip install mkdocs' as mentioned in the official documentation . I only referred to the 'Installing MkDocs' section under 'Manual Installation' as rest of the steps were not required in the context of the task/problem statement.","title":"Installing MkDocs"},{"location":"deploying_report/#selecting-a-theme","text":"MkDocs allows users to use various themes to customise the style and look of the site. For the report's site generated with MkDocs to look nice, I used the 'Material' theme as suggested during the preliminary review of the task. To use this theme with MkDocs, it is required to be installed with pip so, I installed Material theme using the command 'pip install mkdocs-material' as mentioned in the official documentation . Lastly, I specified the theme in MkDocs's configuration YAML file which can be seen in the next section.","title":"Selecting a Theme"},{"location":"deploying_report/#site-configuration","text":"To build the static site, MkDocs needs a YAML file, called mkdocs.yml , be present in the root directory of the project that configures the site structure, site title, pages, themes, etc. It is used to define properties for the site. The YAML file that I wrote for the report is below: site_name: 'Jenkins Pipeline' pages: - Introduction: 'index.md' - Problem Statement: 'problem_statement.md' - Glossary: 'glossary.md' - Setting Up VMs: 'setting_up_vms.md' - Static Analysis: 'static_analysis.md' - Comparing SAST Tools: 'comparing_sast_tools.md' - Setting Up Pipeline: 'setting_up_pipeline.md' - Configuring Webhook: 'configuring_webhook.md' - Deploying the Report: 'deploying_report.md' - Resources: 'resources.md' theme: 'material' site_name defines the title for the site generated by MkDocs. pages defines the various pages that the site will consist of. Within this section, the title for the different pages, along with the Markdown file they are to be associated with, are also declared in a key-value pair structure. theme defines which theme MkDocs should use while generating/serving the static site.","title":"Site Configuration"},{"location":"deploying_report/#deploying-static-site","text":"To generate the static site, in the root directory of the report, I ran the command 'mkdocs build' as mentioned in the documentation. This creates a /site directory containing all the required files to deploy the site. Note : To just preview how the site looks, I used 'mkdocs serve' in the terminal to serve the site locally on my machine. Now, to serve the site I needed a web server for which I installed Apache , following Digital Ocean's documentation , as the server. I chose Apache as it is popular, has great support and is easy to work with in my opinion. The documentation was concise and complete in the context of the task and hence, I went with it. I, however, skipped step 4, 'Setting Up Virtual Hosts', as I was only going to host one site and thus, did not require to configure virtual hosts which are used to serve multiple websites on the same server. Lastly, I copied the contents from static site directory ( /site ) generated with MkDocs to the web root directory ( /var/www/html ) to serve the report as a static site.","title":"Deploying Static Site"},{"location":"glossary/","text":"Glossary There are some terms used in this report which might not be common and/or might have a different meaning in general. This glossary contains a list of such terms along with their intended meaning in the report: Term Description DVNA Damn Vulnerable Node Application; An intentionally vulnerably Node.js application. VM Virtual Machine used to complete the task. Production VM/Server The Virtual Machine used to deploy and Host DVNA. Jenkins Machine/VM The VM that has Jenkins installed on it to execute the pipeline for the task. Jenkins User The system user created on the VM after installing Jenkins. Infrastructure The environment with the two VMs, the Jenkins VM and the Production VM.","title":"Glossary"},{"location":"glossary/#glossary","text":"There are some terms used in this report which might not be common and/or might have a different meaning in general. This glossary contains a list of such terms along with their intended meaning in the report: Term Description DVNA Damn Vulnerable Node Application; An intentionally vulnerably Node.js application. VM Virtual Machine used to complete the task. Production VM/Server The Virtual Machine used to deploy and Host DVNA. Jenkins Machine/VM The VM that has Jenkins installed on it to execute the pipeline for the task. Jenkins User The system user created on the VM after installing Jenkins. Infrastructure The environment with the two VMs, the Jenkins VM and the Production VM.","title":"Glossary"},{"location":"problem_statement/","text":"Problem Statement Setup a basic pipeline (use Jenkins ) for generating a security report for DVNA . The DVNA code should be downloaded from Github and then undergo static analysis. As part of the project understand what is the tech stack for DVNA hence what potential static analysis tools can be applied here. Once a static analysis is done the report should be saved. Next the DVNA should get deployed in a server. To do all of the above just consider 2 virtual machines running in your laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying the DVNA using the pipeline. Do document extensively in markdown and deploy the documentation in a MkDocs website on the second VM. Additionally, there was some inferred task to address in the problem statement: To create a comparitive report about how various SAST tools performed. To create a webhook to trigger the build when a push event occurs on the project repository on GitHub.","title":"Problem Statement"},{"location":"problem_statement/#problem-statement","text":"Setup a basic pipeline (use Jenkins ) for generating a security report for DVNA . The DVNA code should be downloaded from Github and then undergo static analysis. As part of the project understand what is the tech stack for DVNA hence what potential static analysis tools can be applied here. Once a static analysis is done the report should be saved. Next the DVNA should get deployed in a server. To do all of the above just consider 2 virtual machines running in your laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying the DVNA using the pipeline. Do document extensively in markdown and deploy the documentation in a MkDocs website on the second VM. Additionally, there was some inferred task to address in the problem statement: To create a comparitive report about how various SAST tools performed. To create a webhook to trigger the build when a push event occurs on the project repository on GitHub.","title":"Problem Statement"},{"location":"resources/","text":"References These are some references I used along with the ones mentioned implicitly in the report: https://hub.docker.com/_/sonarqube/ https://medium.com/@rosaniline/setup-sonarqube-with-jenkins-declarative-pipeline-75bccdc9075f https://codebabel.com/sonarqube-with-jenkins/amp/ https://github.com/xseignard/sonar-js https://discuss.bitrise.io/t/sonarqube-authorization-problem/4229/2 https://www.sonarqube.org/ https://docs.npmjs.com/cli/audit https://github.com/ajinabraham/NodeJsScan https://retirejs.github.io/retire.js/ https://www.owasp.org/index.php/OWASP_Dependency_Check https://github.com/sonatype-nexus-community/auditjs https://github.com/snyk/snyk#cli https://github.com/nodesecurity/nsp https://github.com/dvolvox/JSpwn https://github.com/dpnishant/jsprime https://github.com/mozilla/scanjs","title":"Resources"},{"location":"resources/#references","text":"These are some references I used along with the ones mentioned implicitly in the report: https://hub.docker.com/_/sonarqube/ https://medium.com/@rosaniline/setup-sonarqube-with-jenkins-declarative-pipeline-75bccdc9075f https://codebabel.com/sonarqube-with-jenkins/amp/ https://github.com/xseignard/sonar-js https://discuss.bitrise.io/t/sonarqube-authorization-problem/4229/2 https://www.sonarqube.org/ https://docs.npmjs.com/cli/audit https://github.com/ajinabraham/NodeJsScan https://retirejs.github.io/retire.js/ https://www.owasp.org/index.php/OWASP_Dependency_Check https://github.com/sonatype-nexus-community/auditjs https://github.com/snyk/snyk#cli https://github.com/nodesecurity/nsp https://github.com/dvolvox/JSpwn https://github.com/dpnishant/jsprime https://github.com/mozilla/scanjs","title":"References"},{"location":"setting_up_pipeline/","text":"Setting Up Pipeline The following is the Jenkinsfile to execute the pipeline: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build\"' } } stage ('Build') { steps { sh ''' export MYSQL_USER=root export MYSQL_DATABASE=dvna export MYSQL_PASSWORD=ayushpriya10 export MYSQL_HOST=127.0.0.1 export MYSQL_PORT=3306 npm install ''' } } stage ('SonarQube Analysis') { environment { scannerHome = tool 'SonarQube Scanner' } steps { withSonarQubeEnv ('SonarQube') { sh '${scannerHome}/bin/sonar-scanner' sh 'cat .scannerwork/report-task.txt > /var/lib/jenkins/reports/sonarqube-report' } } } stage ('NPM Audit Analysis') { steps { sh '/home/chaos/npm-audit.sh' } } stage ('NodeJsScan Analysis') { steps { sh 'nodejsscan --directory `pwd` --output /var/lib/jenkins/reports/nodejsscan-report' } } stage ('Retire.js Analysis') { steps { sh 'retire --path `pwd` --outputformat json --outputpath /var/lib/jenkins/reports/retirejs-report --exitwith 0' } } stage ('Dependency-Check Analysis') { steps { sh '/var/lib/jenkins/dependency-check/bin/dependency-check.sh --scan `pwd` --format JSON --out /var/lib/jenkins/reports/dependency-check-report --prettyPrint' } } stage ('Audit.js Analysis') { steps { sh '/home/chaos/auditjs.sh' } } stage ('Snyk Analysis') { steps { sh '/home/chaos/snyk.sh' } } stage ('Deploy to App Server') { steps { sh 'echo \"Deploying App to Server\"' sh 'ssh -o StrictHostKeyChecking=no chaos@10.0.2.20 \"cd dvna && pm2 stop server.js\"' sh 'ssh -o StrictHostKeyChecking=no chaos@10.0.2.20 \"rm -rf dvna/ && mkdir dvna\"' sh 'scp -r * chaos@10.0.2.20:~/dvna' sh 'ssh -o StrictHostKeyChecking=no chaos@10.0.2.20 \"source ./env.sh && ./env.sh && cd dvna && pm2 start server.js\"' } } } } Stages The pipeline is divided into the following stages which perform specific step(s): Initialization This is just a dummy stage, nothing happens here. Build In this stage, DVNA get built locally on the Jenkins VM. Static Analysis All the stages that follow the Build Stage, except for the last one, consist of performing static analysis on DVNA with various tools. Deployment Finally, the Jenkins VM stops the existing deployment of the App on the Production VM, purges associated files, copies local build over ssh and restarts the deployment reflecting the latest changes.","title":"Setting Up Pipeline"},{"location":"setting_up_pipeline/#setting-up-pipeline","text":"The following is the Jenkinsfile to execute the pipeline: pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build\"' } } stage ('Build') { steps { sh ''' export MYSQL_USER=root export MYSQL_DATABASE=dvna export MYSQL_PASSWORD=ayushpriya10 export MYSQL_HOST=127.0.0.1 export MYSQL_PORT=3306 npm install ''' } } stage ('SonarQube Analysis') { environment { scannerHome = tool 'SonarQube Scanner' } steps { withSonarQubeEnv ('SonarQube') { sh '${scannerHome}/bin/sonar-scanner' sh 'cat .scannerwork/report-task.txt > /var/lib/jenkins/reports/sonarqube-report' } } } stage ('NPM Audit Analysis') { steps { sh '/home/chaos/npm-audit.sh' } } stage ('NodeJsScan Analysis') { steps { sh 'nodejsscan --directory `pwd` --output /var/lib/jenkins/reports/nodejsscan-report' } } stage ('Retire.js Analysis') { steps { sh 'retire --path `pwd` --outputformat json --outputpath /var/lib/jenkins/reports/retirejs-report --exitwith 0' } } stage ('Dependency-Check Analysis') { steps { sh '/var/lib/jenkins/dependency-check/bin/dependency-check.sh --scan `pwd` --format JSON --out /var/lib/jenkins/reports/dependency-check-report --prettyPrint' } } stage ('Audit.js Analysis') { steps { sh '/home/chaos/auditjs.sh' } } stage ('Snyk Analysis') { steps { sh '/home/chaos/snyk.sh' } } stage ('Deploy to App Server') { steps { sh 'echo \"Deploying App to Server\"' sh 'ssh -o StrictHostKeyChecking=no chaos@10.0.2.20 \"cd dvna && pm2 stop server.js\"' sh 'ssh -o StrictHostKeyChecking=no chaos@10.0.2.20 \"rm -rf dvna/ && mkdir dvna\"' sh 'scp -r * chaos@10.0.2.20:~/dvna' sh 'ssh -o StrictHostKeyChecking=no chaos@10.0.2.20 \"source ./env.sh && ./env.sh && cd dvna && pm2 start server.js\"' } } } }","title":"Setting Up Pipeline"},{"location":"setting_up_pipeline/#stages","text":"The pipeline is divided into the following stages which perform specific step(s):","title":"Stages"},{"location":"setting_up_pipeline/#initialization","text":"This is just a dummy stage, nothing happens here.","title":"Initialization"},{"location":"setting_up_pipeline/#build","text":"In this stage, DVNA get built locally on the Jenkins VM.","title":"Build"},{"location":"setting_up_pipeline/#static-analysis","text":"All the stages that follow the Build Stage, except for the last one, consist of performing static analysis on DVNA with various tools.","title":"Static Analysis"},{"location":"setting_up_pipeline/#deployment","text":"Finally, the Jenkins VM stops the existing deployment of the App on the Production VM, purges associated files, copies local build over ssh and restarts the deployment reflecting the latest changes.","title":"Deployment"},{"location":"setting_up_vms/","text":"Setting up VMs Objective The aim of this section is to setup the required infrastructure to perform the task and solve the 6th point of the problem statement . System Configuration The lab setup is of two VMs running Ubuntu 18.04 on VirtualBox as it is an LTS (Long Term Support) version which is a desirable feature for a CI pipline. The realease notes for Ubuntu 18.04 can be found here for additional details. One VM has the Jenkins Infrastructure and the other is used as a Production Server to deploy the application (DVNA) on the server via the Jenkins Pipeline. I installed Ubuntu on both VirtualBox VMs following this documentation . I decided to go with this documentation as it was concise. I, however, chose the 'Normal Installation' under \"Minimal Install Option and Third Party Software\" segment instead of the ones specified in the instructions as otherwise only the essential Ubuntu core components. Additionally, I left out the optional third step \"Managing installation media\" as I did not need the boot media after the installation was complete. Installing Jenkins Jenkins is a Continous Integration (CI) Tool used to automate actions for CI operations for building and deploying applications. Jenkins was used as the tool to build the application deployment pipeline as it was a requisite of the problem statement given. Installed Jenkins following Digital Ocean's documentation . I went along with this particular documentation as it seemed the easiest to follow with clear steps, and I like the style of Digital Ocean's documentations. For this documentation, I didn't skip any step. Choosing the Application The application that was to be analysed and deployed, as required by the problem statment, was DVNA (or Damn Vulnerable Node Application). It is an intentionally vulnerable application written with Node.js and has various security issues designed to illustrate different security concepts. Configuring Production VM To serve DVNA , there were some prerequisites. The following steps conclude how to setup the prerequisites for Jenkins to be able to deploy the application through the pipeline. Setting up DVNA I forked the DVNA repository onto my GitHub account to be able to add files and edit project structure. Then I added a Jenkinsfile to the project repository to configure pipeline stages and execute it. DVNA's documentation specifies MySQL as the database needed so, to to install MySQL for DVNA I again used Digital Ocean's documentation . Under step 3, I skipped the section about provisionally MySQL access for a dedicated user. I created the 'root' user as mentioned in the documentation previously and then went straight to step 4 so as there was no need for an additional user after root . MySQL was insalled the Production VM for a successful deployment of the application. The Jenkins VM need not have MySQL installed as DVNA was only getting built on this machine and not deployed. To not leak the MySQL Server configuration details for the production server, I used a shell script, named env.sh , and placed it in the Production VM in user's home directory ( /home/<username> ). The script gets executed from the pipeline to export the Environment Variables for the application to deploy. The contents of the script (env.sh) to setup environment variables on Production VM are: #!/bin/bash export MYSQL_USER=root export MYSQL_DATABASE=dvna export MYSQL_PASSWORD=<mysql_password> export MYSQL_HOST=127.0.0.1 export MYSQL_PORT=3306 This script is executed through the pipeline in the 'Deploy to App Server' stage. Configuring SSH Access For Jenkins to be able to perform operations and copy application files onto the on the Production VM, ssh configuration was required to allow the Jenkins User to log on to the Production VM. For the same, I switched to the Jenkins User , creates a pair of SSH keys (an extensive article about how user authentication works in SSH with public keys can be found here ) and placed the public key in the Production VM: Switching to Jenkins User sudo su - jenkins Generating new SSH Keys for the Jenkins User ssh-keygen -t ed25519 -C \"<email>\" The public key generated above was added to ~/.ssh/authorized_keys on the Production VM. Note : One could also use the ssh-agent plugin in Jenkins to use a different user to ssh in to the production VM. The credentails for that user will have to be added under Jenkins Credentials Section. Note : ed25519 is used instead of the rsa option as it provides a smaller key while providing the equivalent security of an RSA key.","title":"Setting Up VMs"},{"location":"setting_up_vms/#setting-up-vms","text":"","title":"Setting up VMs"},{"location":"setting_up_vms/#objective","text":"The aim of this section is to setup the required infrastructure to perform the task and solve the 6th point of the problem statement .","title":"Objective"},{"location":"setting_up_vms/#system-configuration","text":"The lab setup is of two VMs running Ubuntu 18.04 on VirtualBox as it is an LTS (Long Term Support) version which is a desirable feature for a CI pipline. The realease notes for Ubuntu 18.04 can be found here for additional details. One VM has the Jenkins Infrastructure and the other is used as a Production Server to deploy the application (DVNA) on the server via the Jenkins Pipeline. I installed Ubuntu on both VirtualBox VMs following this documentation . I decided to go with this documentation as it was concise. I, however, chose the 'Normal Installation' under \"Minimal Install Option and Third Party Software\" segment instead of the ones specified in the instructions as otherwise only the essential Ubuntu core components. Additionally, I left out the optional third step \"Managing installation media\" as I did not need the boot media after the installation was complete.","title":"System Configuration"},{"location":"setting_up_vms/#installing-jenkins","text":"Jenkins is a Continous Integration (CI) Tool used to automate actions for CI operations for building and deploying applications. Jenkins was used as the tool to build the application deployment pipeline as it was a requisite of the problem statement given. Installed Jenkins following Digital Ocean's documentation . I went along with this particular documentation as it seemed the easiest to follow with clear steps, and I like the style of Digital Ocean's documentations. For this documentation, I didn't skip any step.","title":"Installing Jenkins"},{"location":"setting_up_vms/#choosing-the-application","text":"The application that was to be analysed and deployed, as required by the problem statment, was DVNA (or Damn Vulnerable Node Application). It is an intentionally vulnerable application written with Node.js and has various security issues designed to illustrate different security concepts.","title":"Choosing the Application"},{"location":"setting_up_vms/#configuring-production-vm","text":"To serve DVNA , there were some prerequisites. The following steps conclude how to setup the prerequisites for Jenkins to be able to deploy the application through the pipeline.","title":"Configuring Production VM"},{"location":"setting_up_vms/#setting-up-dvna","text":"I forked the DVNA repository onto my GitHub account to be able to add files and edit project structure. Then I added a Jenkinsfile to the project repository to configure pipeline stages and execute it. DVNA's documentation specifies MySQL as the database needed so, to to install MySQL for DVNA I again used Digital Ocean's documentation . Under step 3, I skipped the section about provisionally MySQL access for a dedicated user. I created the 'root' user as mentioned in the documentation previously and then went straight to step 4 so as there was no need for an additional user after root . MySQL was insalled the Production VM for a successful deployment of the application. The Jenkins VM need not have MySQL installed as DVNA was only getting built on this machine and not deployed. To not leak the MySQL Server configuration details for the production server, I used a shell script, named env.sh , and placed it in the Production VM in user's home directory ( /home/<username> ). The script gets executed from the pipeline to export the Environment Variables for the application to deploy. The contents of the script (env.sh) to setup environment variables on Production VM are: #!/bin/bash export MYSQL_USER=root export MYSQL_DATABASE=dvna export MYSQL_PASSWORD=<mysql_password> export MYSQL_HOST=127.0.0.1 export MYSQL_PORT=3306 This script is executed through the pipeline in the 'Deploy to App Server' stage.","title":"Setting up DVNA"},{"location":"setting_up_vms/#configuring-ssh-access","text":"For Jenkins to be able to perform operations and copy application files onto the on the Production VM, ssh configuration was required to allow the Jenkins User to log on to the Production VM. For the same, I switched to the Jenkins User , creates a pair of SSH keys (an extensive article about how user authentication works in SSH with public keys can be found here ) and placed the public key in the Production VM: Switching to Jenkins User sudo su - jenkins Generating new SSH Keys for the Jenkins User ssh-keygen -t ed25519 -C \"<email>\" The public key generated above was added to ~/.ssh/authorized_keys on the Production VM. Note : One could also use the ssh-agent plugin in Jenkins to use a different user to ssh in to the production VM. The credentails for that user will have to be added under Jenkins Credentials Section. Note : ed25519 is used instead of the rsa option as it provides a smaller key while providing the equivalent security of an RSA key.","title":"Configuring SSH Access"},{"location":"static_analysis/","text":"Static Analysis SAST Tools for Node.js Applications The following are some tools that I found to perform SAST on Nodejs Applications: SonarQube Used SonarQube's docker image to run the application with the following command: docker run -d -p 9000:9000 -p 9092:9092 --name sonarqube sonarqube Created a new Access Token for Jenkins in SonarQube under Account > Security . In Jenkins, under Credentials > Add New Credentials the token is saved as a Secret Text type credential. The SonarQube Server section under Manage Jenkins > Configure System , check the Enable injection of SonarQube server configuration as build environment variables option. Provide the URL for SonarQube Server (in our case, localhost:9000) and add the previously saved SonarQube Credentials. Add the following stage in the Jenkinsfile: stage ('SonarQube Analysis') { environment { scannerHome = tool 'SonarQube Scanner' } steps { withSonarQubeEnv ('SonarQube') { sh '${scannerHome}/bin/sonar-scanner' sh 'cat .scannerwork/report-task.txt > /var/lib/jenkins/reports/sonarqube-report' } } } NPM Audit NPM Audit comes along with npm@6 and is not required to be installed seprately. To upgrade npm, if needed, run the following command: npm install -g npm@latest NPM Audit gives a non-zero status code, if it finds any vulnerable dependencies, hence, I ran it through a script to avoid failure of the pipeline. The script is as follows: #!/bin/bash cd /var/lib/jenkins/workspace/node-app-pipeline npm audit --json > /var/lib/jenkins/reports/npm-audit-report echo $? > /dev/null Add the following stage in the Jenkinsfile: stage ('NPM Audit Analysis') { steps { sh '/home/chaos/npm-audit.sh' } } NodeJsScan To install NodeJsScan , use the following command: pip3 install nodejsscan Note : If the package is not getting installed globally, as it will be run by the Jenkins User, run the following command: sudo -H pip3 install nodejsscan . To analyse the Nodejs project, the following command is used: nodejsscan --directory `pwd` --output /var/lib/jenkins/reports/nodejsscan-report Add the following stage in the Jenkinsfile: stage ('NodeJsScan Analysis') { steps { sh 'nodejsscan --directory `pwd` --output /var/lib/jenkins/reports/nodejsscan-report' } } Retire.js To install Retire.js use the following command: npm install -g retire To analyse the project with Retire.js run the following command: retire --path `pwd` --outputformat json --outputpath /var/lib/jenkins/reports/retirejs-report --exitwith 0 Add the following stage in the Jenkinsfile: stage ('Retire.js Analysis') { steps { sh 'retire --path `pwd` --outputformat json --outputpath /var/lib/jenkins/reports/retirejs-report --exitwith 0' } } OWASP Dependency Checker OWASP Dependency Checker comes as an executable for linux. To get the executable, download the archive . Unzip the archive: unzip dependency-check-5.2.4-release.zip To execute the scan, run the following command: /var/lib/jenkins/dependency-check/bin/dependency-check.sh --scan /var/lib/jenkins/workspace/node-app-pipeline --format JSON --out /var/lib/jenkins/reports/dependency-check-report --prettyPrint Note : Copy the unzipped archive to /var/lib/jenkins/ before scanning. Add the following stage in the Jenkinfile: stage ('Dependency-Check Analysis') { steps { sh '/var/lib/jenkins/dependency-check/bin/dependency-check.sh --scan `pwd` --format JSON --out /var/lib/jenkins/reports/dependency-check-report --prettyPrint' } } Auditjs To install Audit.js, use the following command: npm install auditjs -g To perform a scan, run the following command while inside the project directory: auditjs --username ayushpriya10@gmail.com --token <auth_token> /var/lib/jenkins/reports/auditjs-report 2>&1 Auditjs gives a non-zero status code, if it finds any vulnerable dependencies, hence, I ran it through a script to avoid failure of the pipeline. The script is as follows: #!/bin/bash cd /var/lib/jenkins/workspace/node-app-pipeline auditjs --username ayushpriya10@gmail.com --token <auth_token> /var/lib/jenkins/reports/auditjs-report 2>&1 echo $? > /dev/null Note : We use 2>&1 to redirct STDERR output to STDOUT otherwise the Vulnerabilities found will not be written to the report but instead will be printed to console. Add the following stage to the Jenkinsfile: stage ('Audit.js Analysis') { steps { sh '/home/chaos/auditjs.sh' } } Snyk To install Snyk, use the following command: npm install -g snyk Before scanning a project, we need to authenticate Snyk CLI which can be done as follows: snyk auth <AUTH TOKEN> To perform a scan: snyk test Snyk gives a non-zero status code, if it finds any vulnerable dependencies, hence, I ran it through a script to avoid failure of the pipeline. The script is as follows: #!/bin/bash cd /var/lib/jenkins/workspace/node-app-pipeline snyk auth <auth_token> snyk test --json > /var/lib/jenkins/reports/snyk-report echo $? > /dev/null Add the following stage to the pipeline: stage ('Snyk Analysis') { steps { sh '/home/chaos/snyk.sh' } } Other Tools NSP NSP or Node Security Project is now replaced with npm audit starting npm@6 and hence, is unavilable to new users. JSPrime JSPrime lacks a CLI interface and hence, couldn't be integrated into the CI Pipeline. ScanJS (Deprecated) ScanJS is depracated and was throwing an exception while being run via the CLI interface. JSpwn (JSPrime + ScanJs) JSpwn combines both JSPrime and JsScan and has a CLI interface as well. The CLI gave garbage output when ran.","title":"Static Analysis"},{"location":"static_analysis/#static-analysis","text":"","title":"Static Analysis"},{"location":"static_analysis/#sast-tools-for-nodejs-applications","text":"The following are some tools that I found to perform SAST on Nodejs Applications:","title":"SAST Tools for Node.js Applications"},{"location":"static_analysis/#sonarqube","text":"Used SonarQube's docker image to run the application with the following command: docker run -d -p 9000:9000 -p 9092:9092 --name sonarqube sonarqube Created a new Access Token for Jenkins in SonarQube under Account > Security . In Jenkins, under Credentials > Add New Credentials the token is saved as a Secret Text type credential. The SonarQube Server section under Manage Jenkins > Configure System , check the Enable injection of SonarQube server configuration as build environment variables option. Provide the URL for SonarQube Server (in our case, localhost:9000) and add the previously saved SonarQube Credentials. Add the following stage in the Jenkinsfile: stage ('SonarQube Analysis') { environment { scannerHome = tool 'SonarQube Scanner' } steps { withSonarQubeEnv ('SonarQube') { sh '${scannerHome}/bin/sonar-scanner' sh 'cat .scannerwork/report-task.txt > /var/lib/jenkins/reports/sonarqube-report' } } }","title":"SonarQube"},{"location":"static_analysis/#npm-audit","text":"NPM Audit comes along with npm@6 and is not required to be installed seprately. To upgrade npm, if needed, run the following command: npm install -g npm@latest NPM Audit gives a non-zero status code, if it finds any vulnerable dependencies, hence, I ran it through a script to avoid failure of the pipeline. The script is as follows: #!/bin/bash cd /var/lib/jenkins/workspace/node-app-pipeline npm audit --json > /var/lib/jenkins/reports/npm-audit-report echo $? > /dev/null Add the following stage in the Jenkinsfile: stage ('NPM Audit Analysis') { steps { sh '/home/chaos/npm-audit.sh' } }","title":"NPM Audit"},{"location":"static_analysis/#nodejsscan","text":"To install NodeJsScan , use the following command: pip3 install nodejsscan Note : If the package is not getting installed globally, as it will be run by the Jenkins User, run the following command: sudo -H pip3 install nodejsscan . To analyse the Nodejs project, the following command is used: nodejsscan --directory `pwd` --output /var/lib/jenkins/reports/nodejsscan-report Add the following stage in the Jenkinsfile: stage ('NodeJsScan Analysis') { steps { sh 'nodejsscan --directory `pwd` --output /var/lib/jenkins/reports/nodejsscan-report' } }","title":"NodeJsScan"},{"location":"static_analysis/#retirejs","text":"To install Retire.js use the following command: npm install -g retire To analyse the project with Retire.js run the following command: retire --path `pwd` --outputformat json --outputpath /var/lib/jenkins/reports/retirejs-report --exitwith 0 Add the following stage in the Jenkinsfile: stage ('Retire.js Analysis') { steps { sh 'retire --path `pwd` --outputformat json --outputpath /var/lib/jenkins/reports/retirejs-report --exitwith 0' } }","title":"Retire.js"},{"location":"static_analysis/#owasp-dependency-checker","text":"OWASP Dependency Checker comes as an executable for linux. To get the executable, download the archive . Unzip the archive: unzip dependency-check-5.2.4-release.zip To execute the scan, run the following command: /var/lib/jenkins/dependency-check/bin/dependency-check.sh --scan /var/lib/jenkins/workspace/node-app-pipeline --format JSON --out /var/lib/jenkins/reports/dependency-check-report --prettyPrint Note : Copy the unzipped archive to /var/lib/jenkins/ before scanning. Add the following stage in the Jenkinfile: stage ('Dependency-Check Analysis') { steps { sh '/var/lib/jenkins/dependency-check/bin/dependency-check.sh --scan `pwd` --format JSON --out /var/lib/jenkins/reports/dependency-check-report --prettyPrint' } }","title":"OWASP Dependency Checker"},{"location":"static_analysis/#auditjs","text":"To install Audit.js, use the following command: npm install auditjs -g To perform a scan, run the following command while inside the project directory: auditjs --username ayushpriya10@gmail.com --token <auth_token> /var/lib/jenkins/reports/auditjs-report 2>&1 Auditjs gives a non-zero status code, if it finds any vulnerable dependencies, hence, I ran it through a script to avoid failure of the pipeline. The script is as follows: #!/bin/bash cd /var/lib/jenkins/workspace/node-app-pipeline auditjs --username ayushpriya10@gmail.com --token <auth_token> /var/lib/jenkins/reports/auditjs-report 2>&1 echo $? > /dev/null Note : We use 2>&1 to redirct STDERR output to STDOUT otherwise the Vulnerabilities found will not be written to the report but instead will be printed to console. Add the following stage to the Jenkinsfile: stage ('Audit.js Analysis') { steps { sh '/home/chaos/auditjs.sh' } }","title":"Auditjs"},{"location":"static_analysis/#snyk","text":"To install Snyk, use the following command: npm install -g snyk Before scanning a project, we need to authenticate Snyk CLI which can be done as follows: snyk auth <AUTH TOKEN> To perform a scan: snyk test Snyk gives a non-zero status code, if it finds any vulnerable dependencies, hence, I ran it through a script to avoid failure of the pipeline. The script is as follows: #!/bin/bash cd /var/lib/jenkins/workspace/node-app-pipeline snyk auth <auth_token> snyk test --json > /var/lib/jenkins/reports/snyk-report echo $? > /dev/null Add the following stage to the pipeline: stage ('Snyk Analysis') { steps { sh '/home/chaos/snyk.sh' } }","title":"Snyk"},{"location":"static_analysis/#other-tools","text":"NSP NSP or Node Security Project is now replaced with npm audit starting npm@6 and hence, is unavilable to new users. JSPrime JSPrime lacks a CLI interface and hence, couldn't be integrated into the CI Pipeline. ScanJS (Deprecated) ScanJS is depracated and was throwing an exception while being run via the CLI interface. JSpwn (JSPrime + ScanJs) JSpwn combines both JSPrime and JsScan and has a CLI interface as well. The CLI gave garbage output when ran.","title":"Other Tools"}]}